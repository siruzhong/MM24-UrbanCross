2024-02-28 17:05:55.049172: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-28 17:05:55.270663: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-02-28 17:05:56.788152: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /hpc2ssd/softwares/cuda/cuda-12.0/lib64:/opt/slurm/lib
2024-02-28 17:05:56.788319: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /hpc2ssd/softwares/cuda/cuda-12.0/lib64:/opt/slurm/lib
2024-02-28 17:05:56.788356: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
/hpc2hdd/home/xhao390/.local/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /hpc2hdd/home/xhao390/.local/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIlEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE
  warn(f"Failed to load image Python extension: {e}")
/hpc2hdd/home/xhao390/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
2024-02-28 17:06:05,229 Loading vectors from .vector_cache/glove.840B.300d.txt.pt
-------------------------
# Hyper Parameters setting
experiment_name: SWAN
model_name: SWAN
data_name: rsitmd
data_path: ./data/rsitmd_precomp/
image_path: ./rs_data/rsitmd/images/
vocab_path: ./vocab/rsitmd_splits_vocab.json
resnet_ckpt: ./aid_28-rsp-resnet-50-ckpt.pth
resume: False
fix_data: False
step_sample: False
epochs: 50
eval_step: 1
test_step: 0
batch_size: 100
batch_size_val: 100
shard_size: 256
workers: 3
k_fold_nums: 1
k_fold_current_num: 0
embed_dim: 512
margin: 0.2
max_violation: False
grad_clip: 0.0
seed: 0
il_measure: False
word_dim: 300
use_bidirectional_rnn: True
is_finetune: False
num_layers: 1
gpuid: 0
distributed: False
init_method: tcp://localhost:18888
rank: 0
world_size: 2
use_mix_precision: False
logger_name: logs/
ckpt_save_path: checkpoint/
print_freq: 10
lr: 0.0002
lr_update_epoch: 20
lr_decay_param: 0.7
sk_1: 2
sk_2: 3
cross_attn: t2i
agg_func: LogSumExp
lambda_lse: 6.0
lambda_softmax: 9.0
raw_feature_norm: softmax
-------------------------

Start 1th fold, total 1 flod
Generate random samples to ./data/rsitmd_precomp/ complete.
Copy random samples and Cal data info to checkpoint/rsitmd/SWAN/ complete.
len of train_loader is 172, len of val_loader is 43
=> using bidirectional rnn:True
Words: 1330/1349 found in vocabulary; 19 words missing
Total Params:  40462342
Total Requires_grad Params:  16892840
Current lr: 0.0002
2024-02-28 17:06:16,126 Epoch [0][0/172]	Time 7.145	Loss 3978.4634	
2024-02-28 17:06:19,423 Epoch [0][10/172]	Time 0.688	Loss 3850.485	
2024-02-28 17:06:24,288 Epoch [0][20/172]	Time 0.257	Loss 3472.264	
2024-02-28 17:06:29,031 Epoch [0][30/172]	Time 0.394	Loss 2729.9146	
2024-02-28 17:06:33,963 Epoch [0][40/172]	Time 0.839	Loss 2307.1538	
2024-02-28 17:06:38,162 Epoch [0][50/172]	Time 0.226	Loss 1774.5029	
2024-02-28 17:06:42,377 Epoch [0][60/172]	Time 0.332	Loss 1811.997	
2024-02-28 17:06:47,080 Epoch [0][70/172]	Time 0.713	Loss 1325.7722	
2024-02-28 17:06:51,277 Epoch [0][80/172]	Time 0.275	Loss 1532.1047	
2024-02-28 17:06:55,350 Epoch [0][90/172]	Time 0.236	Loss 1126.1315	
2024-02-28 17:07:00,070 Epoch [0][100/172]	Time 0.780	Loss 1119.1892	
2024-02-28 17:07:04,182 Epoch [0][110/172]	Time 0.292	Loss 1115.1	
2024-02-28 17:07:08,350 Epoch [0][120/172]	Time 0.326	Loss 1133.4655	
2024-02-28 17:07:12,926 Epoch [0][130/172]	Time 0.656	Loss 985.39667	
2024-02-28 17:07:17,162 Epoch [0][140/172]	Time 0.298	Loss 718.3286	
2024-02-28 17:07:21,254 Epoch [0][150/172]	Time 0.200	Loss 1041.2144	
2024-02-28 17:07:25,814 Epoch [0][160/172]	Time 0.737	Loss 823.58496	
2024-02-28 17:07:29,669 Epoch [0][170/172]	Time 0.116	Loss 783.42847	

--------------------- start val on training ---------------------
==> start to compute image-caption pairwise distance <==
Calculate the similarity in batches: [0/4]
Calculate the similarity in batches: [1/4]
Calculate the similarity in batches: [2/4]
Calculate the similarity in batches: [3/4]
infer time:0.10
==> end to compute image-caption pairwise distance <==
calculate similarity time: 28.99 s
--------------------- end val on training ---------------------


================ evaluate result on val set =====================
Current => [1/1] fold & [1/50] epochs
Now val score:
i2t => r1i:2.91 r5i:10.71 r10i:15.72 medri:51.00 meanri:153.59
t2i => r1t:2.75 r5t:11.34 r10t:20.68 medrt:30.00 meanrt:77.75
mR:10.68
Best val score:
i2t => r1i:2.91 r5i:10.71 r10i:15.72 medri:51.00 meanri:153.59
t2i => r1t:2.75 r5t:11.34 r10t:20.68 medrt:30.00 meanrt:77.75
mR:10.68
=================================================================

Current lr: 0.0002
2024-02-28 17:08:01,298 Epoch [1][0/172]	Time 1.834	Loss 903.15466	
2024-02-28 17:08:05,354 Epoch [1][10/172]	Time 0.233	Loss 847.81274	
2024-02-28 17:08:09,502 Epoch [1][20/172]	Time 0.189	Loss 802.81445	
2024-02-28 17:08:14,470 Epoch [1][30/172]	Time 0.876	Loss 724.4866	
2024-02-28 17:08:18,734 Epoch [1][40/172]	Time 0.217	Loss 882.08154	
2024-02-28 17:08:22,865 Epoch [1][50/172]	Time 0.192	Loss 632.1185	
2024-02-28 17:08:27,790 Epoch [1][60/172]	Time 0.896	Loss 843.8882	
2024-02-28 17:08:31,958 Epoch [1][70/172]	Time 0.228	Loss 811.3677	
2024-02-28 17:08:36,197 Epoch [1][80/172]	Time 0.210	Loss 728.2518	
2024-02-28 17:08:40,942 Epoch [1][90/172]	Time 0.800	Loss 768.8705	
2024-02-28 17:08:45,236 Epoch [1][100/172]	Time 0.227	Loss 701.64343	
2024-02-28 17:08:49,422 Epoch [1][110/172]	Time 0.197	Loss 861.36865	
2024-02-28 17:08:54,265 Epoch [1][120/172]	Time 0.979	Loss 567.0695	
2024-02-28 17:08:58,534 Epoch [1][130/172]	Time 0.200	Loss 562.0038	
2024-02-28 17:09:02,710 Epoch [1][140/172]	Time 0.208	Loss 539.64136	
2024-02-28 17:09:07,418 Epoch [1][150/172]	Time 0.868	Loss 735.456	
2024-02-28 17:09:11,710 Epoch [1][160/172]	Time 0.217	Loss 663.6919	
2024-02-28 17:09:15,542 Epoch [1][170/172]	Time 0.121	Loss 636.64526	

--------------------- start val on training ---------------------
==> start to compute image-caption pairwise distance <==
Calculate the similarity in batches: [0/4]
Calculate the similarity in batches: [1/4]
Calculate the similarity in batches: [2/4]
Calculate the similarity in batches: [3/4]
infer time:0.10
==> end to compute image-caption pairwise distance <==
calculate similarity time: 28.56 s
--------------------- end val on training ---------------------


================ evaluate result on val set =====================
Current => [1/1] fold & [2/50] epochs
Now val score:
i2t => r1i:4.07 r5i:12.22 r10i:19.21 medri:43.00 meanri:131.96
t2i => r1t:4.05 r5t:15.20 r10t:27.03 medrt:22.00 meanrt:64.42
mR:13.63
Best val score:
i2t => r1i:4.07 r5i:12.22 r10i:19.21 medri:43.00 meanri:131.96
t2i => r1t:4.05 r5t:15.20 r10t:27.03 medrt:22.00 meanrt:64.42
mR:13.63
=================================================================

Current lr: 0.0002
2024-02-28 17:09:46,726 Epoch [2][0/172]	Time 1.794	Loss 783.5513	
2024-02-28 17:09:50,938 Epoch [2][10/172]	Time 0.220	Loss 543.12854	
2024-02-28 17:09:55,004 Epoch [2][20/172]	Time 0.191	Loss 533.88934	
2024-02-28 17:09:59,974 Epoch [2][30/172]	Time 0.880	Loss 554.15826	
2024-02-28 17:10:04,227 Epoch [2][40/172]	Time 0.210	Loss 405.82617	
2024-02-28 17:10:08,510 Epoch [2][50/172]	Time 0.211	Loss 589.1353	
2024-02-28 17:10:13,450 Epoch [2][60/172]	Time 0.933	Loss 628.0787	
2024-02-28 17:10:17,636 Epoch [2][70/172]	Time 0.183	Loss 577.754	
2024-02-28 17:10:21,778 Epoch [2][80/172]	Time 0.184	Loss 521.82227	
2024-02-28 17:10:26,690 Epoch [2][90/172]	Time 0.884	Loss 396.49188	
2024-02-28 17:10:30,886 Epoch [2][100/172]	Time 0.212	Loss 502.8993	
2024-02-28 17:10:35,138 Epoch [2][110/172]	Time 0.220	Loss 667.27045	
2024-02-28 17:10:40,006 Epoch [2][120/172]	Time 0.888	Loss 587.5067	
2024-02-28 17:10:44,138 Epoch [2][130/172]	Time 0.200	Loss 586.163	
2024-02-28 17:10:48,418 Epoch [2][140/172]	Time 0.212	Loss 713.639	
2024-02-28 17:10:53,278 Epoch [2][150/172]	Time 0.889	Loss 616.37354	
2024-02-28 17:10:57,458 Epoch [2][160/172]	Time 0.228	Loss 673.32654	
2024-02-28 17:11:01,114 Epoch [2][170/172]	Time 0.108	Loss 452.3542	

--------------------- start val on training ---------------------
==> start to compute image-caption pairwise distance <==
Calculate the similarity in batches: [0/4]
Calculate the similarity in batches: [1/4]
Calculate the similarity in batches: [2/4]
Calculate the similarity in batches: [3/4]
infer time:0.10
==> end to compute image-caption pairwise distance <==
calculate similarity time: 28.58 s
--------------------- end val on training ---------------------


================ evaluate result on val set =====================
Current => [1/1] fold & [3/50] epochs
Now val score:
i2t => r1i:4.07 r5i:11.64 r10i:20.02 medri:37.00 meanri:112.30
t2i => r1t:4.00 r5t:16.51 r10t:29.52 medrt:20.00 meanrt:56.99
mR:14.30
Best val score:
i2t => r1i:4.07 r5i:11.64 r10i:20.02 medri:37.00 meanri:112.30
t2i => r1t:4.00 r5t:16.51 r10t:29.52 medrt:20.00 meanrt:56.99
mR:14.30
=================================================================

Current lr: 0.0002
2024-02-28 17:11:32,386 Epoch [3][0/172]	Time 1.840	Loss 391.8924	
2024-02-28 17:11:36,562 Epoch [3][10/172]	Time 0.212	Loss 385.80316	
2024-02-28 17:11:40,770 Epoch [3][20/172]	Time 0.220	Loss 319.56152	
2024-02-28 17:11:45,666 Epoch [3][30/172]	Time 0.876	Loss 461.107	
2024-02-28 17:11:49,938 Epoch [3][40/172]	Time 0.216	Loss 566.0351	
2024-02-28 17:11:54,182 Epoch [3][50/172]	Time 0.192	Loss 486.61737	
2024-02-28 17:11:58,954 Epoch [3][60/172]	Time 0.889	Loss 410.792	
2024-02-28 17:12:03,191 Epoch [3][70/172]	Time 0.192	Loss 487.11377	
2024-02-28 17:12:07,370 Epoch [3][80/172]	Time 0.228	Loss 454.1764	
2024-02-28 17:12:12,355 Epoch [3][90/172]	Time 0.906	Loss 722.08435	
2024-02-28 17:12:16,486 Epoch [3][100/172]	Time 0.187	Loss 489.91754	
2024-02-28 17:12:20,766 Epoch [3][110/172]	Time 0.216	Loss 499.19708	
2024-02-28 17:12:25,630 Epoch [3][120/172]	Time 0.868	Loss 471.7336	
2024-02-28 17:12:29,770 Epoch [3][130/172]	Time 0.204	Loss 458.6533	
2024-02-28 17:12:34,007 Epoch [3][140/172]	Time 0.221	Loss 557.47644	
2024-02-28 17:12:38,859 Epoch [3][150/172]	Time 0.965	Loss 603.6278	
2024-02-28 17:12:42,982 Epoch [3][160/172]	Time 0.208	Loss 569.37195	
2024-02-28 17:12:46,738 Epoch [3][170/172]	Time 0.106	Loss 542.96216	

--------------------- start val on training ---------------------
Exception in thread Thread-8:
Traceback (most recent call last):
  File "/hpc2hdd/home/xhao390/.conda/envs/urbanclip/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/hpc2hdd/home/xhao390/.conda/envs/urbanclip/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/hpc2hdd/home/xhao390/.local/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py", line 49, in _pin_memory_loop
    do_one_step()
  File "/hpc2hdd/home/xhao390/.local/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py", line 26, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/hpc2hdd/home/xhao390/.conda/envs/urbanclip/lib/python3.7/multiprocessing/queues.py", line 113, in get
    return _ForkingPickler.loads(res)
  File "/hpc2hdd/home/xhao390/.local/lib/python3.7/site-packages/torch/multiprocessing/reductions.py", line 310, in rebuild_storage_fd
    storage = cls._new_shared_fd_cpu(fd, size)
RuntimeError: unable to resize file <filename not specified> to the right size: Invalid argument (22)

Traceback (most recent call last):
  File "train.py", line 465, in <module>
    main(args_new)
  File "train.py", line 198, in main
    rsum, all_scores = engine.validate(args, val_loader, model)
  File "/hpc2hdd/home/xhao390/py/SWAN-pytorch-main/engine.py", line 124, in validate
    for i, val_data in enumerate(val_loader):
  File "/hpc2hdd/home/xhao390/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/hpc2hdd/home/xhao390/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1316, in _next_data
    idx, data = self._get_data()
  File "/hpc2hdd/home/xhao390/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1277, in _get_data
    raise RuntimeError('Pin memory thread exited unexpectedly')
RuntimeError: Pin memory thread exited unexpectedly
